{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8e7bb8a",
   "metadata": {},
   "source": [
    "# Text representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd6eabf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cbaa3e",
   "metadata": {},
   "source": [
    "## Dummy vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65d3756a",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_docs = [\n",
    "                  \"Dog bites man\", \n",
    "                  \"Man bites dog\", \n",
    "                  \"Dog eats meat.\", \n",
    "                  \"Man eats food\"\n",
    "                  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dec8fb",
   "metadata": {},
   "source": [
    "## One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096672e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf4a0964",
   "metadata": {},
   "source": [
    "## Bag of Words (BoW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "184ca1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dog': 1, 'bites': 0, 'man': 4, 'eats': 2, 'meat': 5, 'food': 3}\n",
      "[[1 1 0 0 1 0]]\n",
      "Bow representation for 'dog and dog are friends': [[0 2 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "bow_rep = count_vect.fit_transform(processed_docs)\n",
    "print(count_vect.vocabulary_)\n",
    "print(bow_rep[0].toarray())\n",
    "temp = count_vect.transform([\"dog and dog are friends\"])\n",
    "print(\"Bow representation for 'dog and dog are friends':\",temp.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c5dc82",
   "metadata": {},
   "source": [
    "## Bag of N-gram (BoN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9183b951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our vocabulary:  {'dog': 3, 'bites': 0, 'man': 12, 'dog bites': 4, 'bites man': 2, 'dog bites man': 5, 'man bites': 13, 'bites dog': 1, 'man bites dog': 14, 'eats': 8, 'meat': 17, 'dog eats': 6, 'eats meat': 10, 'dog eats meat': 7, 'food': 11, 'man eats': 15, 'eats food': 9, 'man eats food': 16}\n",
      "Bow representation for 'dog and dog are friends': [[0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "#n-gram vectorization example with count vectorizer and uni, bi, trigrams\n",
    "count_vect = CountVectorizer(ngram_range=(1,3))\n",
    "\n",
    "#Build a BOW representation for the corpus\n",
    "bow_rep = count_vect.fit_transform(processed_docs)\n",
    "\n",
    "#Look at the vocabulary mapping\n",
    "print(\"Our vocabulary: \", count_vect.vocabulary_)\n",
    "\n",
    "#Get the representation using this vocabulary, for a new text\n",
    "temp = count_vect.transform([\"dog and dog are friends\"])\n",
    "print(\"Bow representation for 'dog and dog are friends':\", temp.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91203e40",
   "metadata": {},
   "source": [
    "## TF-IDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f36e4b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.51082562 1.22314355 1.51082562 1.91629073 1.22314355 1.91629073]\n",
      "['bites' 'dog' 'eats' 'food' 'man' 'meat']\n",
      "Tfidf representation for 'dog and man are friends':\n",
      " [[0.         0.70710678 0.         0.         0.70710678 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "bow_rep_tfidf = tfidf.fit_transform(processed_docs)\n",
    "print(tfidf.idf_) #IDF for all words in the vocabulary\n",
    "print(tfidf.get_feature_names_out()) #All words in the vocabulary.\n",
    "\n",
    "temp = tfidf.transform([\"dog and man are friends\"])\n",
    "print(\"Tfidf representation for 'dog and man are friends':\\n\", temp.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a57463",
   "metadata": {},
   "source": [
    "# Advanced text embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac3618b",
   "metadata": {},
   "source": [
    "## Pre-trained word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7df11422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading pre-trained model: glove-wiki-gigaword-50...\n",
      "Download complete!\n",
      "\n",
      "Words most similar to 'car':\n",
      "  truck: 0.9209\n",
      "  cars: 0.8870\n",
      "  vehicle: 0.8834\n",
      "  driver: 0.8464\n",
      "  driving: 0.8384\n",
      "\n",
      "Word that doesn't match in the list 'breakfast cereal dinner lunch':\n",
      "  The odd one out is: cereal\n",
      "\n",
      "Analogy: King - Man + Woman = ?\n",
      "  The result is: queen (score: 0.8524)\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# The name of the smaller pre-trained model to download.\n",
    "# This model is a 50-dimensional GloVe model trained on Wikipedia.\n",
    "# It's much, much faster to download and perfect for testing.\n",
    "model_name = \"glove-wiki-gigaword-50\"\n",
    "print(f\"Downloading pre-trained model: {model_name}...\")\n",
    "wv = api.load(model_name)\n",
    "print(\"Download complete!\")\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# Using the KeyedVectors model\n",
    "# -----------------------------------------------------------\n",
    "\n",
    "# 1. Find words most similar to a given word\n",
    "# The `most_similar` method returns a list of tuples.\n",
    "print(\"\\nWords most similar to 'car':\")\n",
    "similar_words = wv.most_similar('car', topn=5)\n",
    "for word, score in similar_words:\n",
    "    print(f\"  {word}: {score:.4f}\")\n",
    "\n",
    "# 2. Find the word that doesn't belong\n",
    "print(\"\\nWord that doesn't match in the list 'breakfast cereal dinner lunch':\")\n",
    "odd_one_out = wv.doesnt_match(\"breakfast cereal dinner lunch\".split())\n",
    "print(f\"  The odd one out is: {odd_one_out}\")\n",
    "\n",
    "# 3. Solve a word analogy\n",
    "print(\"\\nAnalogy: King - Man + Woman = ?\")\n",
    "analogy_result = wv.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)\n",
    "for word, score in analogy_result:\n",
    "    print(f\"  The result is: {word} (score: {score:.4f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
